# -*- coding: utf-8 -*-
"""facial emotion recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V445ZzOFTNAQfy9E8fSG4kb6k5OEIwpR
"""

from google.colab import drive
drive.mount('/content/drive')

# Import các thư viện cần thiết
import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import cv2

folder_path = '/content/drive/MyDrive/CS105.L21.KHCL-DHMT/dataset/'

def show_sample_images(folder_path, expression='fear'):
    plt.figure(figsize=(12, 12))
    plt.style.use('dark_background')

    for i in range(1, 10):
        plt.subplot(3, 3, i)
        img_path = os.path.join(folder_path, "train", expression, os.listdir(folder_path + "train/" + expression)[i])
        img = load_img(img_path, target_size=(48, 48))
        plt.imshow(img)
        plt.axis('off')
    plt.show()
show_sample_images(folder_path, expression='fear')

# Tạo các Data Generator
datagen_train = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode="nearest"
)
datagen_val = ImageDataGenerator(rescale=1./255)

train_set = datagen_train.flow_from_directory(
    folder_path + "train",
    target_size=(48, 48),
    color_mode="grayscale",
    batch_size=64,
    class_mode='categorical',
    shuffle=True
)
val_set = datagen_val.flow_from_directory(
    folder_path + "validation",
    target_size=(48, 48),
    color_mode="grayscale",
    batch_size=64,
    class_mode='categorical',
    shuffle=False
)

# Xây dựng mô hình nhận diện cảm xúc
emotion_model = Sequential()

# Các lớp convolutional
emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))
emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
emotion_model.add(MaxPooling2D(pool_size=(2, 2)))
emotion_model.add(Dropout(0.25))

emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
emotion_model.add(MaxPooling2D(pool_size=(2, 2)))
emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
emotion_model.add(MaxPooling2D(pool_size=(2, 2)))
emotion_model.add(Dropout(0.25))

# Flatten + Fully connected layers
emotion_model.add(Flatten())
emotion_model.add(Dense(1024, activation='relu'))
emotion_model.add(Dropout(0.5))
emotion_model.add(Dense(7, activation='softmax'))

emotion_model_info = emotion_model.fit_generator(train_set,
                                                 steps_per_epoch=28709 // 64,
                                                 epochs=48,
                                                 validation_data=val_set,
                                                 validation_steps=7178 // 64)

# Biên dịch mô hình
emotion_model.compile(
    loss='categorical_crossentropy',
    optimizer=Adam(learning_rate=0.0001, decay=1e-6),
    metrics=['accuracy']
)

# Huấn luyện mô hình
emotion_model_info = emotion_model.fit(
    train_set,
    steps_per_epoch=len(train_set),
    epochs=48,
    validation_data=val_set,
    validation_steps=len(val_set)
)

# Lưu mô hình
emotion_model.save('emotion_model.h5')

"""Độ chính xác và mất mác"""

# Hiển thị biểu đồ loss và accuracy
plt.figure(figsize=(20, 10))
plt.subplot(1, 2, 1)
plt.title('Loss')
plt.plot(emotion_model_info.history['loss'], label='Train Loss')
plt.plot(emotion_model_info.history['val_loss'], label='Validation Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.title('Accuracy')
plt.plot(emotion_model_info.history['accuracy'], label='Train Accuracy')
plt.plot(emotion_model_info.history['val_accuracy'], label='Validation Accuracy')
plt.legend()

plt.show()

# Hàm phát hiện khuôn mặt và cắt ảnh
def facecrop(image_path):
    facedata = '/content/haarcascade_frontalface_alt.xml'
    cascade = cv2.CascadeClassifier(facedata)

    img = cv2.imread(image_path)

    try:
        minisize = (img.shape[1], img.shape[0])
        miniframe = cv2.resize(img, minisize)
        faces = cascade.detectMultiScale(miniframe)

        if len(faces) == 0:
            print("No face detected.")
            return None

        for (x, y, w, h) in faces:
            sub_face = img[y:y+h, x:x+w]
            cv2.imwrite('capture.jpg', sub_face)
            return 'capture.jpg'

    except Exception as e:
        print(f"Error: {e}")
        return None

# Hàm hiển thị cảm xúc
def emotion_analysis(emotions):
    objects = ('angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise')
    y_pos = np.arange(len(objects))

    plt.bar(y_pos, emotions, align='center', alpha=0.5)
    plt.xticks(y_pos, objects)
    plt.ylabel('Percentage')
    plt.title('Emotion Analysis')
    plt.show()

# Chụp ảnh bằng webcam (Colab)
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
    async function takePhoto(quality) {
        const div = document.createElement('div');
        const capture = document.createElement('button');
        capture.textContent = 'Capture';
        div.appendChild(capture);

        const video = document.createElement('video');
        video.style.display = 'block';
        const stream = await navigator.mediaDevices.getUserMedia({video: true});

        document.body.appendChild(div);
        div.appendChild(video);
        video.srcObject = stream;
        await video.play();
        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);
        await new Promise((resolve) => capture.onclick = resolve);
        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.getContext('2d').drawImage(video, 0, 0);
        stream.getVideoTracks()[0].stop();
        div.remove();
        return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

# Dự đoán cảm xúc
def predict_emotion(image_path):
    cropped_face = facecrop(image_path)
    if not cropped_face:
        print("No face to analyze.")
        return

    img = load_img(cropped_face, color_mode="grayscale", target_size=(48, 48))
    x = img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x /= 255

    predictions = emotion_model.predict(x)
    emotion_analysis(predictions[0])

    plt.imshow(load_img(image_path))
    plt.axis('off')
    plt.show()

# Chụp ảnh và phân tích cảm xúc
photo_path = take_photo()
predict_emotion(photo_path)